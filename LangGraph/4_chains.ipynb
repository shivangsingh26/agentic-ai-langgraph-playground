{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain in Langgraph\n",
    "\n",
    "In this section we will build a simple chain using langgraph that uses 4 important concepts\n",
    "\n",
    "- How to use chat message as a graph state\n",
    "\n",
    "- How to use chat models in graph nodes\n",
    "\n",
    "- How to bind tools to our LLM in chat models\n",
    "\n",
    "- How to execute tool calls in graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ChatMessages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: User\n",
      "\n",
      "What's the weather like today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "The weather today is sunny with a high of 75°F.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content=f\"Hello! How can I assist you today?\" , name = \"LLMModel\")]\n",
    "messages.append(HumanMessage(content=\"What's the weather like today?\", name = \"User\"))\n",
    "messages.append(AIMessage(content=\"The weather today is sunny with a high of 75°F.\", name = \"LLMModel\"))\n",
    "# In graph state this appending part is taken care by use of reducers\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivangsingh/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 1,\n",
       "  'prompt_tokens': 69,\n",
       "  'total_tokens': 70,\n",
       "  'completion_time': 0.007000217,\n",
       "  'prompt_time': 0.00249089,\n",
       "  'queue_time': None,\n",
       "  'total_time': 0.009491107},\n",
       " 'model_name': 'llama-3.3-70b-versatile',\n",
       " 'system_fingerprint': 'fp_c06d5113ec',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tools\n",
    "\n",
    "- They are simple functions/external API's that the LLM can call\n",
    "\n",
    "- They enable LLM's to take action instead of just generating text.\n",
    "\n",
    "- Examples:\n",
    "    - search the web\n",
    "    - write to a DB\n",
    "    - do calculations\n",
    "    - call APIs\n",
    "    - run Python code\n",
    "    - fetch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int, b:int)-> int:\n",
    "    \"\"\"\n",
    "    Add a and b\n",
    "    Args:\n",
    "        a(int) : first_int\n",
    "        b(int) : second_int\n",
    "\n",
    "    Returns:\n",
    "        int\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x119ddbec0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x119eec230>, model_name='llama-3.3-70b-versatile', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets bind our \"add()\" tool to our  llm\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2+2\", name=\"Krish\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 2},\n",
       "  'id': 'mgv2y5gaw',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using messages with state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    message:list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Routers\n",
    "\n",
    "- They are special type of nodes, whose job is to look at current state, choose one of many possible next nodes and route the execution there\n",
    "\n",
    "- This allows LangGraph to behave like:\n",
    "\n",
    "    - decision trees\n",
    "\n",
    "    - conditional workflows\n",
    "\n",
    "    - multi-agent orchestration\n",
    "\n",
    "    - branch logic\n",
    "\n",
    "    - state-based control flow\n",
    "\n",
    "- So basically graphs introduce \"intelligence\" or \"logic branching\" into our workflows\n",
    "\n",
    "- There are 2 ways to create a router\n",
    "\n",
    "    1) Logic based - Python function where you hardcode  the route.\n",
    "\n",
    "    2) LLM Based - Let the model decide which route to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "class State(TypedDict):\n",
    "    message:Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducers with add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Please tell me how I can help', additional_kwargs={}, response_metadata={}, name='LLMModel')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add_message is a reducer\n",
    "\n",
    "initial_messages = [AIMessage(content=f\"Please tell me how I can help\", name= \"LLMModel\")]\n",
    "messages.append(HumanMessage(content=f\"I want to learn coding\", name= \"Krish\"))\n",
    "\n",
    "initial_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Which programming language you want to learn', additional_kwargs={}, response_metadata={}, name='LLMModel')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = AIMessage(content=f\"Which programming language you want to learn\", name=\"LLMModel\")\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Please tell me how I can help', additional_kwargs={}, response_metadata={}, name='LLMModel', id='0f4a1144-a8a1-432a-81f1-619ce748faff'),\n",
       " AIMessage(content='Which programming language you want to learn', additional_kwargs={}, response_metadata={}, name='LLMModel', id='dd421fcf-b9a5-4015-a2a1-aa69188070d6')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reducers add_message is to append instead of override\n",
    "add_messages(initial_messages, ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_tool(state:State):\n",
    "    return {messages : [llm_with_tools.invoke(state[\"message\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAQAElEQVR4nOydCXgT1drHz0y2tmm6t7RNC23pAi1aloJwWaoUkE9BCvRe+AD1irggIIjgchER9X6gXhRFEKtyL6LAp6iAooDstKgUWpYWCnSnC3Rv0iTNNnNPkjZN2slMktPA2MyP5ynJOWdOMv+c5Z2zvXySJAGHs/ABBwKcfEhw8iHByYcEJx8SnHxIoMpXWqAqypU31Wu0GlKnJkAXKwgnMYCRhFUYxiNJPYbhoEu4IQonSQLruBZgGCD1hiwxiwyBOQH8nzRfaMzNIgRCYoZ/XQIhQi+eQIh5SXj9BoqTRkkAAphzdt/5oy352c0KuY4kSIEA54twoQe8daiLVW44z5B/N/kwmAzDoazmu++4QxwAc2IeMNw+0TVDQt/tC0OJMEPKLj8JjmMEvNzwI1hdIvLga7SkRqXTagiCAB5evOgk8QN/CwaO47B8uUebzx1tJPQgJMJj+ITAyIEi8GemtYE89ePtqhsqvY6ISvKe/Fgfhy53TL4v/1mhlOkSR/qOmx4IeheFZxXZP9XCov3UmhggtPcqB+T7ZEVxSD+PmUukoPdy4tv6gt+bx6T3SR5rV5tor3wfLy+6PyN00F+8gRuwZUXx3FejfAN5jCntkm/zi0VPvR0r9ATuw6evlAxPCxo60Yc+GQ6Y2PpSyfhZoW6lHeSZ9TG/HaprqdPRJ2OQb/tb5SGRooEj3KLOdmHUQ0G736+gT0Mn37kjzapW/Yxe3VfQMHS8r8gT3/NhJU0aevkak0b4AjcmY2nfWxVtNAlsynfxhIzQkWNn9jb7ziG8fXGJr2DfJzW2EtiWL6s5tN+d7i8mTpxYVVUFHKS4uHjKlCnANSSN8qkqUdqKtSmfvFmbMumOFr2ampqmpibgOFeuXAEuI2WiP46Bm9dVlLHUIy43LijgQ3jfBJc8z0JLc9euXT/99FN5eXl0dPTIkSMXLlyYl5f37LPPwthp06alpqZu2LABlqk9e/bk5ORUV1fHxMSkp6dnZGSYckhLS1uwYMGxY8fgVY8++uiOHTsM95mS8sILL8ydOxf0NEJP/PJpWWQ8RV2klq80XyFw2VDA7t27t23btmzZstGjR584cWLz5s1isfiJJ57YuHEjDNy3b59UaujroYJQuFWrVsEfsqys7J133gkLC4OXwCiBQPDDDz+MGDECijhs2DCY4PDhw/D3AK5B4idoqlNTRlHLJ2vQwmEc4Bpyc3MTExNNrdX06dOHDx+uVFI0LuvWrVMoFOHh4cBYsvbv33/mzBmTfFAvX1/fFStWgDuCJEBQVexI5dWo9QIh8wOJcyQnJ2/atOnNN98cMmTIuHHjIiIiKJPBOg7LaXZ2NqzjphBTqTQBfwBwp/CU8HRaPWUUtXyGUU9XqQfmzJkDa+vJkyfXrl3L5/Nhb/v8888HB1uNVsJhzKVLl2o0msWLF8OiJ5FInnzyScsEQqHdg0rIYMbhWMooavlEXny1klpvdHAcn26kpKTk7NmzmZmZra2tH3zwgWWawsLCgoKCLVu2wAbOFCKXy0NCQsDdQCUn4MA1ZRS1fGJfQUuDBrgG2MYPHDiwf//+MUagLrAf6JKmubkZ/jXrVWIEXgLuBrAn4IuoewLqKhoR79mmcFXpO3jw4MqVK0+dOtXS0pKVlQXtD9gawvCoqCj499dff83Pz4eywnoNLRKZTAa73ffeew/aN9AwpMywb9++9fX1sBM3t5I9CzSBA0Oo2wpq+e75iwTOuTTUuKQAvvbaa1Cd5cuXQ/PtrbfeglYetE5gOOxDpk6dunXrVtixhIaGvv3225cvXx4/fjy05hYtWgSNPiir2fSzZMyYMYMHD4Yd8aFDh4ALUMp1cYPFlFE2h0s/W1USEukx7dlw4N4U5rQe2XVr8fuxlLE2+9f4oZLKGzaf9dyHnMMNgaE2HyFsTpOnzgzOP9OSd6JlyP3UY1a3bt2aPXs2ZZS3tzfsTCmjYLWFjxzANfzHCGWUYSLYRj2DthFlm2BC1qiFExW2YunmOo7srL1xQb7wXer+TqfT1dbWUka1tbV5eHhQRsEOwXX2h9wIZRTsgnx8qCcuYDj8vSmjdr17E85oz301EtiAYaro89Wl/RLEE+fdHYPr7nLzWtuPn1U99y86a4nh2WLBW9HXcmWqFlcZMWzmwBfVo6cxrNxgfjSbNDd0+/+VATdj2xvlEfFeyWMZJirtmudtvKXZ+W7F4g2xAAPuwCcvl6TOCEm8j3l+0d5VBqUFSliYB4/zH5Pem2c/Kq6qft5e3Tfe+6H5dq0VcmSJkB5kri7hC/DJj4WG9/cAvY7d71Y21atHTwm5d5y9i/4cXqD28xc1ZYVKOAEaP0QydnoQ+POTd1KWn90sa9AEhXvOetGxSW0nl0ce2HarqkipaSOEItzLhyeWCPgiDOMB8/JI05pE00pIUwiOw1E84yueoSBbfwvrBaCmt5gxjy7rR7ulNmXL42F662WThvTAYrGlBXwBT6MmlDKdUq7XtOnh5wSGC/+6MAI4PoTopHwmWhv1Z4801VW2KVt0Gg2UBCes5YPZAxKzCgFWgR1YLcC1DITjpnB80PJy4+NDZ2JTOM4jCb1VDphxVS5BdXMCPoYLMDgb4R8iuGeMf0Sc89M6SPLdAR588MGdO3cGBrK0v2L7ynr4aAif8wBb4eRDgpMPCbbLp9Vq4aQ4YCuslo8wWjqmnpedsFo+ltdcwMmHCKu/HMsbPsCVPkQ4+ZDg5EOCkw8JtsvHdR3Ow5U+JDj5kODkQwKazZx8zsOVPiQ4+ZDg5EOCkw8JbsQFCa70IcHj8SQSpDOmXA3bp4paWloAi2F31eDzYf0FLIaTDwlOPiQ4+ZDg5EOC7YYLJ5/zcKUPCU4+JDj5kODkQ4KTDwlOPiQ4+ZDg5EOCkw8J9svHxl1Fa9eu3b9/v+mLGTZgGcFxPCcnB7AMNi5aX7hwYVRUFG4EPvbCv1A+Wwet3V3YKF9ISMiECRMsQ6B806ZNA+yDpVsm5s2b169fP/NbqVSanp4O2AdL5YMTbFOnTjVviJk0aZKfnx9gH+zdsDNnzhxTexceHj5jxgzAShzoeXMONjXWaTVt7ZaEhbccw/Zu025v2EGSRMemb2MIbPr1esLKtU6HRx2cZ9yubN7wbeEVB+fDa7HKm5VFxUXhYeFxcXHmHHDTNnFg5YfHvNe83RtPN/9EpssNyUiLqG7J+CJcIvYYM9Pekm6XfNk/NuVnNWE8jMfHNCqiiwrtu8Pbv4rFvnCcAARu3KFvvYO843U3+TrTGKMMXp0IqCJmOLqxU1vc8CGGT7P84sbPMuRh+jibt2v8S1J8ogm+YT8+rtPogyM8M5Yynx7HLF/eCdnZgw0T5kpD+t6540LvMnrwzYcV0hjh5MdD6RMyyHfphOKPQ7WzX4kG7sf3H1X4BQqmPRdGk4ah6zh/vCFiAMNBRL2VMdNCa8pV9GkY5GtTaRNHsNFiuAOE9IONFVacR6cgg3yEDgi9gNsCbQaFXE2TgGHEhYRmiDsePtcO7MQJ2p6Vc/FJB0l9Pk8nnHx0YEbThCYBo3yYexzZRw18hqE/spBRPnaf0eRi9HqS5Cqv82Cm5s8mdsjnzrXXUPYQS58b117DNAGOWPrcGIKwcPZNBZPZ7NaFD7nts+1mxj1AbvtIN2/7DEOqNAlAj/Ld97snTLrP9Dp9xoQvd3wOWIMT38fqlFQqGOXDWGK4/LD3m3XvrAF3Goy+7v1pKu+1ay50RGkLw1A8ebefOkpLi+cvmPXxR9syP9906VJeaJ+w2bMfHzI4ZfWaFZWVFQMGJC1ZvHJAAp3bumXLn754MRe+OHz4wKdbv4qPG5CdfXL7l5nlFaW+vn6xsQlLl7zcp0/7vARNlOMwmB52VF5kTFuaP978r8cfe/rYkZykQcmffb5p44frX37pjUO/nBEJRR9tepc+h43vZw4cOGjSpIePHz0HtTt3/o/X31gJ336z++c1q9ffvl2z8aP1ppQ0UU5gWJtEqwCjfD1WddPSJg8dMhx+n/vHTVAoFI88kpE4cBCfzx83Lq2o6JpDC722/fuTcWPHZ8ycA8tXUtK9zy1c/vvvWYXG2k0T5RQMpceOnreHuo7IyCjTC7HRs01MdKzpraeHp1ar1WgccGpWUnIDVnnz24R4Q8UvLCygj3ICkulXZR7vozz23Qm6nODq9IGura2tarVaJOp02eDlZZiOUSoVNFHANdjR87LsqcPkRKqtrXMCTGFUJzAgiCYKOAfG0HXYUfpYJh9sLhPiBxYUXDKHmF7H9I+jiQLOQaJ3Heyw+6TSyKtX83PzcpqaGqenz8rKPvHdd7tkclnehXNbPnkfdkpxsQkwGU2UM2AAse1jy3Dp1IdnXL9+deVLi95ZvwnaJXX1tf//7Y6Pt2yANl3KsJFPLVhsSkYT5RSw+NEJyLDGZdMLN2YsifEJdJWjbZbznzeKxqYHD071tZWAccDKvQfrmWDLYP3lyxf+sWqZrdivduyFZjC44xg8W6JNVN6h0nfPPYMzM3fair0r2hkhcdRFGneq5w0LZZ0vYJJE63kJ0q3H6hlhkA/H3Hqw3mg0c2tcnMVYedGmigg31q8HSp872309UPrcuu1DXt/n5iuEAL3pYUfl5bANtzwSCaYhAx6G89x0uAUiFPIEAoThUr6AV1PUCtwVgiBiaDdVMcjn30d49VwTcEvO7K8TeeKeAXRpGOT72zKpokmXc7AZuBlw3rQkXz7jmSj6ZHbt5922powv5EfGiwNCRFq9rlsWFOtAsO4jNca1XiRNMox6dIdiZ0pHEGbcDYxRhQPMotezyMJyR2/3nHEMqFtBWaG8ua7t6XX9GZt9e3eT79taU1fZptOQWm3XeV/jYw3WXRfQxeG4UebOnchY1069wyN5hxNti9sj2/9g7S7PDVulcHO2plVkmPUmoPbd7Raf0pEhabym/WG+/bPw9kW4fB7OE2A+QYLZL9p17gnbnWtPnjz566+/5pxrOwnn3hgJTj4kWO7tiSt9SLBaPtKwG5vgsfipkfMWgwQnHxKcqyckuNKHBCcfEpx8SHBtHxJc6UOCkw8JTj4kOPmQ4ORDgpMPCU4+JDj5kODMZiS40ocEJx8SbPcWExwcDFgMq+XT6/W1tbWAxXC+ipDg5EOCkw8JTj4kOPmQ4ORDgu3yQdsFsBiu9CHByYcE2+WDgy6AxXClDwlOPiQ4+ZDg5EOCkw8JTj4k2LiraMmSJVlZWebD8nEcJwgCvj1//jxgGWx0MLt06dKIiAi8A2BUsG/fvoB9sFG+2NjYMWPGWFYLWPRSU1MB+2Cvc+3IyEjzW/g6IyMDsA+WyieVStPS0kyvYcOXkpJi8hTNNtjrXHv27Nkm7+7w76xZswAr6UnDpaVWX1el0qgJs1/H9t3IuMHPc+c+Z4tAQLUvusPvtGjSqCePt528J2GQsjY4v04GOl15W+ffQfteafNbzMrfBh8HOB8PCBUG2xXawwAABm5JREFUSXvMTzOq4XIjT3HuUENTg1avM563Y/TOQ+jJ9m3fVpu52/fid7lnHMcIaz+aZn0MZ1+SRMelWJd8QLft+1306o75KFa+EPf25ScMkwyf5A8QcF6+4982XDvboiMIgQff29/TP8LHy/fP4X1bqyaaK2XyeqVaqYViRsR5TnkqzLmsnJGvoVz7zeYK+Dv7h/uEDUD69e46zdXKupJGrVo3NC1g5P84fC8Oy3d4R+31PFlAmE/4IJaeL+AEUMTqwlqfAMG8Vx0zzh2T7+iuuhsX5QNS+4HeyI0zlQI++fc1UfZf4oB8ezdXV5e3JT7QO7UzARXk4+QTa6PsTG+vfD//+1bFNdWAVDY+ePYsZedqcEA8ttquO7XLbC7NV5UVKNxBO0hUSphKpT+4/bY9ie2S7/BXNUFRd+vc7rtAwti+xZfsOjeOWb4D224DDA/p70byQbx8Pb58s5wxGbN8FYWKkP69x0axk+jhofIWbUsdwxIRBvl+P2A4vM9f6gVYSauiacXq+y5cPgJcgNBLcPjrW/RpGOS7lisTeYuAW+If5tNQo6ZPwyCfUqYLkPoAtyQo2geOgzTdpqu/dANWLbUkHArxC3dVzZXJG378ZWPZzUsaTVtC3MgJqfNDgg02ec3t4g0fz3n+mW3HTm3Pv3rS1ydk8D0TH5q4yHScUN6lwwePfqpSyRIHjE0dPRe4EpyHXz7dNC7Dpp8yutJXdFnmuiPD9Xr91m3PFZflzpz6youLd3qLAz7KnF/fUAkMZxAaNmJ9u2/dkHsfXL8ma07G2pPZX18sMDRwNbeLdu55PWXIQ68s+y5l8MP7DmwArgTj43W09ZdOPnmjBsNddex1acWF2vqy/81YOyB+lI8kcOrk58Vefqd/221OkJw0PnlQGp8v6B89NNBfWllVCAPP/PGdn2/oxPuf9PLyiY0Zdl9KOnAlGE6olHQTzXSVF9Z81516XVZ+kccTxMWkmN7CkVEoU0lZnjlBRPhA82sPD4mqTQ5f1DfeDO0TYw6PlCYCV4JhOL2PSTr5YNEjXCafqq1Vr9dCs8My0FvcOeJm+OrdUCplQYGdM3BCoSdwJYSOJAhnz6wPDBO6ru2TeAfCm58/16rxYvT7CeusVttmfqtWu8p3ZzsEIZbQ2W108iUO8z29tw64BmlYvEaj8vPrExTQPgPZ0FhlWfoo8fcLu1J4Gk5dmoS+ci0LuBI4CRMWRVfA6X5tgdhwZn19mRy4gLj+wwfEjfp27z+bmm+1Kpqz/9jz4da/n839kf6q5KQJ8Elj74ENcJytqOT8mT/2AFcC57yGTKA7NpxhotI3UAjvLihKAlzA/Hnv/5bz/VffvFZ+83JwUL+hyZPHjmKYz02Iu2/Kg0t+O/v9ytdHwi547l/Xbv78GRf5Qrt9rVkgwj1prV6G4dKLp2XZ++sTx/fmEWZbXD99MyRCmP4cnfc4hqY6eawPbGRuF7ndmfXAMJ+pp9cO2LPKIH6Y5Pr5lj6x1ON9sBV/fd1EyiidTgMtO4zKWU1ocMzipz8DPccXO5aXVlykjNJq1QIBRe8pFHi8/tIBYIPi36v9gplPobBrriPzH6Vify/pIOpHP5msnjJcrVGJbNhlPB5fLO7J8VeFskWvo94BolIrPEViiggMg0871JfIdCVnby7aEAuYsEs+jQpkrioaNDEauAdXjpUljw0Y/QjzrLldcx2wDKWkBV05xjx43Qsoyq4KDPOwRztg/wK1kQ/7DXnAv+BoGejVXDleERDGn7Vcamd6x1YZnDvScvaX+v4jpSJvVh/u4xyFxyv8+whmvejAOkyH17jkHms+81M9nIiKGeHkqiQWUn2lqamqJTJe/MizoQ5d6OQCtS9Wl6qUerG/Z/Qwxz6PbVRfaWy5Lcd52CNPScNiHF5g5/z6vht5ylPf16oUOhzHRGKBJMRbEuzlKWF7pdYo9a0NKnmdUt2q1moJgQAkjfQbPS3AudyQt8WQ4MAXt6pKVPDpWmd0Y4QBB0YJjYtGMarw7qHdwzpCrGMMK0wxrD2wPcrK6xGPhwtFvKBwwaiHg/tEIS3p7PldRapWw0RG53vc6JgJtC/KJXEMs1yKi2OdDsAtFuUafWBZrIQ2q2P5ZU1LoM0um9pXRIOuHplNl8MLecDTkwd61HsF2109sRy2e4thOZx8SHDyIcHJhwQnHxKcfEj8FwAA//+aCfN3AAAABklEQVQDAJq8lT5ljA4uAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "builder=StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_tool\", llm_tool)\n",
    "\n",
    "builder.add_edge(START, \"llm_tool\")\n",
    "builder.add_edge(\"llm_tool\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Invocation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m messages = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is 2 plus 2?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[32m      6\u001b[39m     message.pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3050\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3048\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3050\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3051\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3064\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2633\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2632\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2640\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Shivang/Shivang_Codes/Agentic-AI-BootCamp/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mllm_tool\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_tool\u001b[39m(state:State):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {messages : [llm_with_tools.invoke(state[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m])]}\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'",
      "During task with name 'llm_tool' and id 'e41df629-ca35-ba61-490e-6e2924ee4c51'"
     ]
    }
   ],
   "source": [
    "## Invocation\n",
    "from pprint import pprint\n",
    "messages = graph.invoke({\"message\" : \"What is 2 plus 2?\"})\n",
    "\n",
    "for message in message:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Tool Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m builder = StateGraph(State)\n\u001b[32m      7\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mllm_tool\u001b[39m\u001b[33m\"\u001b[39m, llm_tool)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m, ToolNode(\u001b[43mtools\u001b[49m))\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Add Edge\u001b[39;00m\n\u001b[32m     11\u001b[39m builder.add_edge(START, \u001b[33m\"\u001b[39m\u001b[33mllm_tool\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "# tools_condition is used to decide at runtime whether you want to call a tool or not\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_tool\", llm_tool)\n",
    "builder.add_node(\"tool\", ToolNode(tools))\n",
    "\n",
    "# Add Edge\n",
    "builder.add_edge(START, \"llm_tool\")\n",
    "builder.add_conditional_edges(\n",
    "    \"llm_tool\",\n",
    "    # If latest condition is from the chatbot which is the assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message(result) from assistant is not a tool call -> tools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph_builder = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic-AI-BootCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
